{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import torch, nn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import warnings\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(input_sequences, output_sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list() # instantiate X and y\n",
    "    for i in range(len(input_sequences)):\n",
    "        # find the end of the input, output sequence\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out - 1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(input_sequences): break\n",
    "        # gather input and output of the pattern\n",
    "        seq_x, seq_y = input_sequences[i:end_ix], output_sequence[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x), y.append(seq_y)\n",
    "        # print(X,y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'LSTM' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lstm \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlstm_models_pt/naics_11_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevised_processed_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m all0 \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNAICS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m11\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\gmcco\\anaconda3\\envs\\cs373\\lib\\site-packages\\torch\\serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[0;32m   1015\u001b[0m                      map_location,\n\u001b[0;32m   1016\u001b[0m                      pickle_module,\n\u001b[0;32m   1017\u001b[0m                      overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1018\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gmcco\\anaconda3\\envs\\cs373\\lib\\site-packages\\torch\\serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[0;32m   1427\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\gmcco\\anaconda3\\envs\\cs373\\lib\\site-packages\\torch\\serialization.py:1415\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'LSTM' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "lstm = torch.load('lstm_models_pt/naics_11_model.pt')\n",
    "df = pd.read_csv('revised_processed_data.csv')\n",
    "all0 = df[df['NAICS'] == 11]\n",
    "# Do not change\n",
    "pred_len = 2\n",
    "X = all0.drop(columns=['TOT_EMP','NAICS','YEAR'])\n",
    "y = all0['TOT_EMP'].values\n",
    "feed_days = 8\n",
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_trans = ss.fit_transform(X)\n",
    "y_trans = mm.fit_transform(y.reshape(-1, 1)) \n",
    "X_ss, y_mm = split_sequences(X_trans, y_trans, feed_days, pred_len)\n",
    "X_train = X_ss[:-pred_len]\n",
    "X_test = X_ss[-pred_len:]\n",
    "\n",
    "y_train = y_mm[:-pred_len]\n",
    "y_test = y_mm[-pred_len:]\n",
    "X_train_tensors = torch.Tensor(X_train)\n",
    "X_test_tensors = torch.Tensor(X_test)\n",
    "\n",
    "y_train_tensors = torch.Tensor(y_train)\n",
    "y_test_tensors = torch.Tensor(y_test)\n",
    "X_train_tensors_final = torch.reshape(X_train_tensors,   \n",
    "                                   (X_train_tensors.shape[0], feed_days, \n",
    "                                   X_train_tensors.shape[2]))\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  \n",
    "                                   (X_test_tensors.shape[0], feed_days, \n",
    "                                   X_test_tensors.shape[2])) \n",
    "naics_titles = np.array(['Agriculture, Forestry, Fishing and Hunting',\n",
    "       'Mining, Quarrying, and Oil and Gas Extraction', 'Utilities',\n",
    "       'Construction', 'Manufacturing', 'Wholesale Trade', 'Retail Trade',\n",
    "       'Transportation and Warehousing', 'Information',\n",
    "       'Finance and Insurance', 'Real Estate and Rental and Leasing',\n",
    "       'Professional, Scientific, and Technical Services',\n",
    "       'Management of Companies and Enterprises',\n",
    "       'Administrative and Support and Waste Management and Remediation Services',\n",
    "       'Educational Services', 'Health Care and Social Assistance',\n",
    "       'Arts, Entertainment, and Recreation',\n",
    "       'Accommodation and Food Services',\n",
    "       'Other Services (except Public Administration)',\n",
    "       'Federal, State, and Local Government'],\n",
    "      dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Do not change this cell\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m \u001b[43mlstm\u001b[49m(X_test_tensors_final[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;66;03m# get the last sample\u001b[39;00m\n\u001b[0;32m      3\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m test_predict\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m mm\u001b[38;5;241m.\u001b[39minverse_transform(test_predict)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lstm' is not defined"
     ]
    }
   ],
   "source": [
    "# Do not change this cell\n",
    "test_predict = lstm(X_test_tensors_final[-1].unsqueeze(0)) # get the last sample\n",
    "test_predict = test_predict.detach().numpy()\n",
    "test_predict = mm.inverse_transform(test_predict)\n",
    "test_predict = test_predict[0].tolist()\n",
    "\n",
    "test_target = y_test_tensors[-1].detach().numpy() # last sample again\n",
    "test_target = mm.inverse_transform(test_target.reshape(1, -1))\n",
    "test_target = test_target[0].tolist()\n",
    "\n",
    "#Plotting\n",
    "plt.figure(figsize=(10,6)) #plotting\n",
    "a = [x for x in range(16)]\n",
    "plt.plot(a, 16, label='Actual data')\n",
    "c = [x for x in range(16-pred_len-1, len(y))]\n",
    "pred_trend = np.insert(test_predict,0,y[-pred_len-1])\n",
    "plt.plot(c, pred_trend, label='Prediction for 2022-2023 data')\n",
    "plt.xticks([i for i in range(19)])\n",
    "plt.axvline(x=16, c='r', linestyle='--')\n",
    "plt.xlabel(\"Years Since 2005\")\n",
    "plt.ylabel(\"Total Employment\")\n",
    "plt.title(f\"Total Employment across {naics_titles[0]} over time\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
